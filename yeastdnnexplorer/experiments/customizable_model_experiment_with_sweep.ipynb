{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to experiement with our customizable model. We train an instance of it, and then later we perform a hyperparameter sweep to find optimal hyperparameter values using the optuna library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "from pytorch_lightning import Trainer, LightningModule, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "from torchsummary import summary\n",
    "\n",
    "from yeastdnnexplorer.data_loaders.synthetic_data_loader import SyntheticDataLoader\n",
    "from yeastdnnexplorer.ml_models.simple_model import SimpleModel\n",
    "from yeastdnnexplorer.ml_models.customizable_model import CustomizableModel\n",
    "\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from yeastdnnexplorer.probability_models.generate_data import (\n",
    "    perturbation_effect_adjustment_function_with_tf_relationships,\n",
    ")\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining checkpoints and loggers for the model. Checkpoints tell pytorch when to save instances of the model (that can be loaded and inspected later) and loggers tell pytorch how to format the metrics that the model logs during its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoints for the model\n",
    "# tells it when to save snapshots of the model during training\n",
    "# Callback to save the best model based on validation loss\n",
    "\n",
    "# this one works for simple model\n",
    "# best_model_checkpoint = ModelCheckpoint(\n",
    "#     monitor=\"val_loss\",\n",
    "#     mode=\"min\",\n",
    "#     filename=\"best-model-{epoch:02d}-{val_loss:.2f}\",\n",
    "#     save_top_k=1,\n",
    "# )\n",
    "\n",
    "best_model_checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_mse\",\n",
    "    mode=\"min\",\n",
    "    filename=\"best-model-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "# Callback to save checkpoints every 5 epochs, regardless of performance\n",
    "periodic_checkpoint = ModelCheckpoint(\n",
    "    filename=\"periodic-{epoch:02d}\",\n",
    "    every_n_epochs=2,\n",
    "    save_top_k=-1,  # Setting -1 saves all checkpoints\n",
    ")\n",
    "\n",
    "# define loggers for the model\n",
    "tb_logger = TensorBoardLogger(\"logs/tensorboard_logs\")\n",
    "csv_logger = CSVLogger(\"logs/csv_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an instance of the customizable model. We are using perturbation_effect_adjustment_function_with_tf_relationships to adjust the means of the generated data based on which combinations of transcription factors are bound to the gene in question.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, Y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:252: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val, Y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, Y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | r2            | R2Score    | 0     \n",
      "1 | activation    | ReLU       | 0     \n",
      "2 | input_layer   | Linear     | 1.8 K \n",
      "3 | hidden_layers | ModuleList | 10.3 K\n",
      "4 | output_layer  | Linear     | 429   \n",
      "5 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "12.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 K    Total params\n",
      "0.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89229535652488bb0beb58d17b38cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb06fe9971ec44b09a2172fec7623a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e79cf0827e14ff798bf393c447002d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a8aca609314682a12577d9ba05db6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c22ae98b94470c824a7cc99840d8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ddeeea5c924ed5816b537163a7be65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df87bfbc2024089b7e4080b360abb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9042fd6b479b41158117e25f9a610458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a18feafdf749e382cd965f0810559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9e498b107442eb83920c3052e70f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8d3d77f8ef42f198f7809a7018938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cb6b4eca30428aaee5c2bc9b19de80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f95d3286b8b4de99c8cbda13f45f34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mse            1.7528094053268433\n",
      "       test_nrmse           0.20540115237236023\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Printing test results...\n",
      "[{'test_mse': 1.7528094053268433, 'test_nrmse': 0.20540115237236023}]\n",
      "Printing model summary...\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 13, 128]           1,792\n",
      "              ReLU-2              [-1, 13, 128]               0\n",
      "           Dropout-3              [-1, 13, 128]               0\n",
      "            Linear-4               [-1, 13, 64]           8,256\n",
      "              ReLU-5               [-1, 13, 64]               0\n",
      "           Dropout-6               [-1, 13, 64]               0\n",
      "            Linear-7               [-1, 13, 32]           2,080\n",
      "              ReLU-8               [-1, 13, 32]               0\n",
      "           Dropout-9               [-1, 13, 32]               0\n",
      "           Linear-10               [-1, 13, 13]             429\n",
      "================================================================\n",
      "Total params: 12,557\n",
      "Trainable params: 12,557\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tf_relationships_dict = {\n",
    "    0: [2, 4, 7],\n",
    "    1: [8],\n",
    "    2: [3, 9],\n",
    "    3: [1, 6],\n",
    "    4: [5],\n",
    "    5: [0, 2, 8],\n",
    "    6: [4],\n",
    "    7: [1, 4],\n",
    "    8: [6],\n",
    "    9: [0, 3, 8],\n",
    "}\n",
    "\n",
    "data_module = SyntheticDataLoader(\n",
    "    batch_size=32,\n",
    "    num_genes=4000,\n",
    "    signal_mean=3.0,\n",
    "    signal=[0.5] * 10,  # old: [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    n_sample=[1, 2, 2, 4, 4],  # sum of this is num of tfs\n",
    "    val_size=0.1,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    max_mean_adjustment=3.0,\n",
    "    adjustment_function=perturbation_effect_adjustment_function_with_tf_relationships,\n",
    "    tf_relationships=tf_relationships_dict,\n",
    ")\n",
    "\n",
    "num_tfs = sum(data_module.n_sample)  # sum of all n_sample is the number of TFs\n",
    "\n",
    "model = CustomizableModel(\n",
    "    input_dim=num_tfs,\n",
    "    output_dim=num_tfs,\n",
    "    lr=0.01,\n",
    "    hidden_layer_num=3,\n",
    "    hidden_layer_sizes=[128, 64, 32],\n",
    "    activation=\"ReLU\",\n",
    "    optimizer=\"Adam\",\n",
    "    L2_regularization_term=0.0,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    deterministic=True,\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=[best_model_checkpoint, periodic_checkpoint],\n",
    "    logger=[tb_logger, csv_logger],\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "test_results = trainer.test(model, datamodule=data_module)\n",
    "print(\"Printing test results...\")\n",
    "print(test_results)  # this prints all metrics that were logged during the test phase\n",
    "\n",
    "# print summary of model\n",
    "print(\"Printing model summary...\")\n",
    "summary(model, (num_tfs, num_tfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a TF relationships dictionary to be used while training models in our hyperparameter sweep. It is important that we use the same relationships for each of the models we train since the only things being varied in the hyperparameter sweep should be the hyperparameters themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_relationships_dict = {\n",
    "    0: [2, 4, 7],\n",
    "    1: [8],\n",
    "    2: [3, 9],\n",
    "    3: [1, 6],\n",
    "    4: [5],\n",
    "    5: [0, 2, 8],\n",
    "    6: [4],\n",
    "    7: [1, 4],\n",
    "    8: [6],\n",
    "    9: [0, 3, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform our hyperparameter sweep using the optuna library, we need to define an objective function that reutnrs a scalar value. We then minimize this obective function during the hyperparamter sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # model hyperparameters\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    hidden_layer_num = trial.suggest_categorical(\"hidden_layer_num\", [1, 2, 3, 5])\n",
    "    activation = trial.suggest_categorical(\n",
    "        \"activation\", [\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\"]\n",
    "    )\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    L2_regularization_term = trial.suggest_categorical(\n",
    "        \"L2_regularization_term\", [0, 0.1, 0.01]\n",
    "    )  # change to categorical?\n",
    "    dropout_rate = trial.suggest_categorical(\n",
    "        \"dropout_rate\", [0, 0.3, 0.5]\n",
    "    )  # change to categorical?\n",
    "\n",
    "    # data module hyperparameters\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 128])\n",
    "\n",
    "    # training hyperparameters\n",
    "    max_epochs = trial.suggest_categorical(\n",
    "        \"max_epochs\", [2]\n",
    "    )  # can keep this low for sanity check\n",
    "\n",
    "    # defining what to pass in for the hidden layer sizes list based on the number of hidden layers\n",
    "    hidden_layer_sizes_configurations = {\n",
    "        1: [[64], [256]],\n",
    "        2: [[64, 32], [256, 64]],\n",
    "        3: [[256, 128, 32]],\n",
    "        5: [[512, 256, 128, 64, 32]],\n",
    "    }\n",
    "    hidden_layer_sizes = trial.suggest_categorical(\n",
    "        f\"hidden_layer_sizes_{hidden_layer_num}_layers\",\n",
    "        hidden_layer_sizes_configurations[hidden_layer_num],\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"About to create model with the following hyperparameters:\")\n",
    "    print(f\"lr: {lr}\")\n",
    "    print(f\"hidden_layer_num: {hidden_layer_num}\")\n",
    "    print(f\"hidden_layer_sizes: {hidden_layer_sizes}\")\n",
    "    print(f\"activation: {activation}\")\n",
    "    print(f\"optimizer: {optimizer}\")\n",
    "    print(f\"L2_regularization_term: {L2_regularization_term}\")\n",
    "    print(f\"dropout_rate: {dropout_rate}\")\n",
    "    print(f\"batch_size: {batch_size}\")\n",
    "    print(f\"max_epochs: {max_epochs}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # create data module\n",
    "    data_module = SyntheticDataLoader(\n",
    "        batch_size=batch_size,\n",
    "        num_genes=4000,\n",
    "        signal_mean=3.0,\n",
    "        signal=[0.5] * 10,  # old: [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "        n_sample=[1, 2, 2, 4, 4],  # sum of this is num of tfs\n",
    "        val_size=0.1,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        max_mean_adjustment=3.0,\n",
    "        adjustment_function=perturbation_effect_adjustment_function_with_tf_relationships,\n",
    "        tf_relationships=tf_relationships_dict,\n",
    "    )\n",
    "\n",
    "    num_tfs = sum(data_module.n_sample)  # sum of all n_sample is the number of TFs\n",
    "\n",
    "    # create model\n",
    "    model = CustomizableModel(\n",
    "        input_dim=num_tfs,\n",
    "        output_dim=num_tfs,\n",
    "        lr=lr,\n",
    "        hidden_layer_num=hidden_layer_num,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        optimizer=optimizer,\n",
    "        L2_regularization_term=L2_regularization_term,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "\n",
    "    # create trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        deterministic=True,\n",
    "        accelerator=\"cpu\",\n",
    "        callbacks=[\n",
    "            best_model_checkpoint\n",
    "        ],  # not using periodic checkpoint as that would be way too many checkpoints, can add back if we choose a specific hyperparam config that we want to look more closely at\n",
    "        logger=[tb_logger, csv_logger],\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # get best validation loss from the model\n",
    "    return trainer.callback_metrics[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the hyperparater sweep and print out what we found to be the optimal set of hyperparaters. Note that this will create a very large amount of output since we are training an instance of the model for every possible combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-18 10:30:40,965] A new study created in memory with name: no-name-a994b30b-aa3d-4830-8de9-152b9aaaab76\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.001\n",
      "hidden_layer_num: 1\n",
      "hidden_layer_sizes: [64]\n",
      "activation: ReLU\n",
      "optimizer: Adam\n",
      "L2_regularization_term: 0.01\n",
      "dropout_rate: 0.5\n",
      "batch_size: 32\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:231: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, Y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:234: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val, Y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, Y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | ReLU       | 0     \n",
      "1 | input_layer   | Linear     | 896   \n",
      "2 | hidden_layers | ModuleList | 0     \n",
      "3 | output_layer  | Linear     | 845   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d797b865104ddc8617612ff21482c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc397be9e2894596bfb9899d082f5206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebefb99e5ade41e7b2df6c94c8862616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e30b6c8a44edaabd57e62125838a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:31:04,540] Trial 0 finished with value: 4.347833156585693 and parameters: {'lr': 0.001, 'hidden_layer_num': 1, 'activation': 'ReLU', 'optimizer': 'Adam', 'L2_regularization_term': 0.01, 'dropout_rate': 0.5, 'batch_size': 32, 'max_epochs': 2, 'hidden_layer_sizes_1_layers': [64]}. Best is trial 0 with value: 4.347833156585693.\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256, 128, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.1\n",
      "hidden_layer_num: 3\n",
      "hidden_layer_sizes: [256, 128, 32]\n",
      "activation: LeakyReLU\n",
      "optimizer: RMSprop\n",
      "L2_regularization_term: 0.1\n",
      "dropout_rate: 0.3\n",
      "batch_size: 128\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory logs/tensorboard_logs/lightning_logs/version_60/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | LeakyReLU  | 0     \n",
      "1 | input_layer   | Linear     | 3.6 K \n",
      "2 | hidden_layers | ModuleList | 37.0 K\n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "41.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.0 K    Total params\n",
      "0.164     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330d5fcc57514ee6886b77ede16523c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0a285072494d7da9c48289075f4910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3957ba9871468bbf7f4cfc35e981aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cb41fe686c4e6a9fb3b892afc9733b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:31:25,804] Trial 1 finished with value: 49579.48828125 and parameters: {'lr': 0.1, 'hidden_layer_num': 3, 'activation': 'LeakyReLU', 'optimizer': 'RMSprop', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_3_layers': [256, 128, 32]}. Best is trial 0 with value: 4.347833156585693.\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.1\n",
      "hidden_layer_num: 1\n",
      "hidden_layer_sizes: [64]\n",
      "activation: Tanh\n",
      "optimizer: Adam\n",
      "L2_regularization_term: 0.1\n",
      "dropout_rate: 0.3\n",
      "batch_size: 32\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | Tanh       | 0     \n",
      "1 | input_layer   | Linear     | 896   \n",
      "2 | hidden_layers | ModuleList | 0     \n",
      "3 | output_layer  | Linear     | 845   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc4727d3dad4d9384c52c18310dfd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6411211f38492987f4db22a88323c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70562067c7564f31a02e7e80ef97162a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ebae09795d41c388fb4cc02db3fb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:31:48,495] Trial 2 finished with value: 2.718580961227417 and parameters: {'lr': 0.1, 'hidden_layer_num': 1, 'activation': 'Tanh', 'optimizer': 'Adam', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 32, 'max_epochs': 2, 'hidden_layer_sizes_1_layers': [64]}. Best is trial 2 with value: 2.718580961227417.\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [512, 256, 128, 64, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.1\n",
      "hidden_layer_num: 5\n",
      "hidden_layer_sizes: [512, 256, 128, 64, 32]\n",
      "activation: Tanh\n",
      "optimizer: SGD\n",
      "L2_regularization_term: 0\n",
      "dropout_rate: 0.3\n",
      "batch_size: 128\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | Tanh       | 0     \n",
      "1 | input_layer   | Linear     | 7.2 K \n",
      "2 | hidden_layers | ModuleList | 174 K \n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "182 K     Trainable params\n",
      "0         Non-trainable params\n",
      "182 K     Total params\n",
      "0.729     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420db7d8c28846adb2931babfcab3845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce981f8ac564d908b75bfaf21f050de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f55b71e181b43229b0883a279dd0e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522198a66442444290382c58cf8c44e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:32:10,222] Trial 3 finished with value: 2.8252861499786377 and parameters: {'lr': 0.1, 'hidden_layer_num': 5, 'activation': 'Tanh', 'optimizer': 'SGD', 'L2_regularization_term': 0, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_5_layers': [512, 256, 128, 64, 32]}. Best is trial 2 with value: 2.718580961227417.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.01\n",
      "hidden_layer_num: 5\n",
      "hidden_layer_sizes: [512, 256, 128, 64, 32]\n",
      "activation: Tanh\n",
      "optimizer: RMSprop\n",
      "L2_regularization_term: 0.1\n",
      "dropout_rate: 0.3\n",
      "batch_size: 128\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | Tanh       | 0     \n",
      "1 | input_layer   | Linear     | 7.2 K \n",
      "2 | hidden_layers | ModuleList | 174 K \n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "182 K     Trainable params\n",
      "0         Non-trainable params\n",
      "182 K     Total params\n",
      "0.729     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe6e0ee69284fb0bbf6b779e6007c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd8044311dc429dbed26cc59b9e3431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdfe044ce93491aba9b9210713416ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33a692c805247b08668a0f29675e1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:32:32,349] Trial 4 finished with value: 2.3827872276306152 and parameters: {'lr': 0.01, 'hidden_layer_num': 5, 'activation': 'Tanh', 'optimizer': 'RMSprop', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_5_layers': [512, 256, 128, 64, 32]}. Best is trial 4 with value: 2.3827872276306152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RESULTS======================================================================\n",
      "Best hyperparameters: {'lr': 0.01, 'hidden_layer_num': 5, 'activation': 'Tanh', 'optimizer': 'RMSprop', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_5_layers': [512, 256, 128, 64, 32]}\n",
      "Best loss: 2.3827872276306152\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter optimization using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Get the best hyperparameters and their corresponding values\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(\"\\n\" * 5)\n",
    "print(\"RESULTS\" + (\"=\" * 70))\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best loss: {best_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
